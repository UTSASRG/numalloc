\section{Discussion}
\label{sec:limit}

This section describes some limitations of \NM{}. First, \NM{} may consume more memory than some popular allocators, especially when transparent huge pages are enabled. \NM{} currently allocates a big chunk (larger than a huge page) from the OS, then the OS will satisfy the memory allocations with huge pages when transparent huge pages are enabled. Although this method reduces the possible system call overhead and enjoys the performance benefits caused by reducing TLB misses, it does introduce more memory consumption. That is, the whole huge page will be wasted even if applications only use a small portion of huge pages. However, we believe that the memory overhead can be further reduced by more fine-grained management, such as TEMERAIRE's mechanism. We leave this implementation to our future work.

% However, we believe that this shortcoming is tolerable, when memory is not the major concern. 
%As shown in Figure~\ref{fig:remoteAccess}, \NM{} significantly reduces the number of TLB misses by trading with medium memory consumption. 


% Second, \NM{}'s interleaved heap cannot always achieve performance improvement due to the following reason. Although the interleaved heap may avoid memory controller congestion caused by concurrent accesses from multiple child threads, it introduces unnecessary overhead for the initial thread since it is forced to have some remote accesses. 
%(2) Although \NM{} avoids the change of programs to utilize the interleaved heap, it imposes additional overhead to identify the callsites for potentially shared objects. 
% Therefore, users should decide whether to enable the interleaved heap or not. However, this is an easy task, since the interleaved heap may have a harmful impact when the serial phase is a big portion of the execution. Therefore, we think that this shortcoming is totally acceptable given its predictability. 

Second, NUMAlloc is designed with explicit thread binding, where people may be concerned that it conflicts with the OS scheduler. In fact, based on our understanding, this should not be a big issue due to the following reasons. (1) \NM{}'s thread binding does not exclude OS-based scheduling, as it only binds a thread to a node rather than a core. (2) \NM{} allows users to adjust the binding flexibly via a configuration file to meet the needs of different workloads.
% although currently \NM{} only supports node-interleaved and node-saturate binding. But adding more flexible binding will be just pure engineering effort. 
(3) The thread binding is even suitable for server applications with thousands of threads, as \NM{}'s binding balances the workload among different physical nodes. 
%Based on our analysis, the memory consumption is caused by \NM{}'s bag mechanism, especially with transparent huge page support. Currently, \NM{} employs one MB as a bag, which indicates that objects of each size will occupy at least of 1 MB, when transparent huge page support is enabled. Further, \NM{}'s design achieves a fast lookup on the metadata, but will utilize more memory unfortunately. We will investigate whether reducing the size of a bag could help reduce the memory consumption in the future.

%The second limitation is that \NM{} will crash less often by preallocating a huge chunk of memory from the OS in the beginning. If an invalid reference is landed within a pre-allocated range, a program will not crash, different from other allocators. Instead, \NM{} aims to achieve the high performance over the reliability. Therefore, we believe that this limitation is acceptable.  

% \todo{How does this work when there are multiple OS processes (each with a bunch of threads) on the same machine?  Also, Iâ€™m concerned that this might conflict with other thread binding that the user might do, e.g., through OpenMP.  The paper does not seem to talk about these cases.}

\begin{comment}
\todo{NUMAalloc may not suitable for the situation for the system has thousands of threads. But maybe still okay, as these threads are balanced distributed to different nodes.

NUMAlloc can be useful for certain applications and system configurations and appears to be well-crafted. 

Maybe we could say that numa support is a daunting task, but it is actually not. This paper shows how to use and embedded these mechanisms in order to choose a better result. 
Interleaving shared objects similarly can make sense (e.g. as in the applications used in the evaluation of the paper) but is not easy to accept that it will universally work well or better than other techniques. As a different case from the one above, consider a server where tens-hundreds of different applications are running, possibly in containers/VMs, starting and finishing dynamically. What does interleaving shared objects say for such cases?

}

\end{comment}
